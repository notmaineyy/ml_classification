{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "DrnyJ6GkYWHv",
        "imXAIJC-pHlh",
        "Xyd2Lo8IClRB"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Training Portion\n",
        "https://www.tensorflow.org/tutorials/images/classification"
      ],
      "metadata": {
        "id": "J3-ex8CSC2hS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Splitting of data into training and validation sets"
      ],
      "metadata": {
        "id": "cDL9NG62DBAn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import PIL\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential"
      ],
      "metadata": {
        "id": "NuoPRDXbAd39"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "img_height = 100 #960\n",
        "img_width = 350\n",
        "#1350\n",
        "data_dir = '/content/drive/MyDrive/2023_internship/dataset_20200803/onlyAugmentedFlir/flipped'"
      ],
      "metadata": {
        "id": "3BGMurdqC9fe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset and perform class-wise splitting\n",
        "dataset = tf.keras.utils.image_dataset_from_directory(\n",
        "    data_dir,\n",
        "    validation_split=0.2,\n",
        "    subset=\"training\",\n",
        "    seed=123,\n",
        "    image_size=(img_height, img_width),\n",
        "    batch_size=batch_size)\n",
        "\n",
        "class_names = dataset.class_names\n",
        "num_classes = len(class_names)\n",
        "\n",
        "# Create balanced validation and testing datasets\n",
        "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    data_dir,\n",
        "    validation_split=0.2,\n",
        "    subset=\"validation\",\n",
        "    seed=123,\n",
        "    image_size=(img_height, img_width),\n",
        "    batch_size=batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EHy3CknwDAET",
        "outputId": "3ab9c74c-3d33-46ae-ab2f-8792f6ffc195"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1021 files belonging to 15 classes.\n",
            "Using 817 files for training.\n",
            "Found 1021 files belonging to 15 classes.\n",
            "Using 204 files for validation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Only needed if dataset is too huge, and need to train model with half of the dataset first"
      ],
      "metadata": {
        "id": "AW_xnQ88idUp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the number of samples in the training dataset\n",
        "num_samples = dataset.cardinality().numpy()\n",
        "\n",
        "# Split the dataset into two parts\n",
        "split_index = num_samples // 2\n",
        "\n",
        "# Create two separate datasets for the first and second parts\n",
        "train_ds_part1 = dataset.take(split_index)\n",
        "train_ds_part2 = dataset.skip(split_index)"
      ],
      "metadata": {
        "id": "2mqJFqExRlaQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preparing of Model"
      ],
      "metadata": {
        "id": "pRln56p4DGDL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# just to see if there are any extra folders\n",
        "print(class_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yU6DJJ9qDGwE",
        "outputId": "4decbad6-d30f-4658-9a64-876f03bda11a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Barge', 'BulkCarrier', 'ContainerShip', 'Cruise', 'Dredger', 'Ferry', 'HarbourLaunch-PilotVessel', 'LNG-LPG', 'RORO', 'Sampan', 'SupplyVessel', 'Tanker-Bunker', 'Trawler-FishingVessel', 'Tugboat', 'Yacht']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ship_categories = class_names\n",
        "\n",
        "ship_dict = {index: category for index, category in enumerate(class_names)}\n",
        "\n",
        "# print(ship_dict)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5DRBqPbD_nkM",
        "outputId": "f30e7138-6e7f-43fd-9bf4-3f7629db6155"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: 'Barge', 1: 'BulkCarrier', 2: 'ContainerShip', 3: 'Cruise', 4: 'Dredger', 5: 'Ferry', 6: 'HarbourLaunch-PilotVessel', 7: 'LNG-LPG', 8: 'RORO', 9: 'Sampan', 10: 'SupplyVessel', 11: 'Tanker-Bunker', 12: 'Trawler-FishingVessel', 13: 'Tugboat', 14: 'Yacht'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "dataset = dataset.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "metadata": {
        "id": "IyWyYpXwDIWc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normalization_layer = layers.Rescaling(1./255)"
      ],
      "metadata": {
        "id": "EhzdDmLUDMI3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1 = Sequential([\n",
        "  layers.Rescaling(1./255, input_shape=(img_height, img_width, 3)),\n",
        "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Flatten(),\n",
        "  layers.Dense(128, activation='relu'),\n",
        "  layers.Dense(num_classes)\n",
        "])"
      ],
      "metadata": {
        "id": "DLD-inDODNxP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "2L5glfbKDPcZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWV7qH9LDQ7R",
        "outputId": "a300c4ec-660e-4bb0-bbaa-679330d6abbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " rescaling_7 (Rescaling)     (None, 100, 350, 3)       0         \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 100, 350, 16)      448       \n",
            "                                                                 \n",
            " max_pooling2d_9 (MaxPooling  (None, 50, 175, 16)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_10 (Conv2D)          (None, 50, 175, 32)       4640      \n",
            "                                                                 \n",
            " max_pooling2d_10 (MaxPoolin  (None, 25, 87, 32)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (None, 25, 87, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_11 (MaxPoolin  (None, 12, 43, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 33024)             0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 128)               4227200   \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 15)                1935      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,252,719\n",
            "Trainable params: 4,252,719\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### For transfer learning purposes\n",
        "(training existing models)"
      ],
      "metadata": {
        "id": "PtOL-wnCjBFx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "model_1 = load_model('/content/drive/MyDrive/flir_model_withSharpenedBrightened.keras')"
      ],
      "metadata": {
        "id": "ULR_eA9_yDhf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Training"
      ],
      "metadata": {
        "id": "cwGI_4j1DXFm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "epochs=50\n",
        "\n",
        "# EarlyStopping will stop training if validation loss doesn't improve\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss', patience=5, verbose=1, restore_best_weights=True)\n",
        "\n",
        "# Train your model\n",
        "history = model_1.fit(\n",
        "    dataset,\n",
        "    validation_data=val_ds,\n",
        "    epochs=epochs,\n",
        "    callbacks=[early_stopping]\n",
        ")\n",
        "\n",
        "# Find the index where validation loss is minimized\n",
        "best_epoch = history.history['val_loss'].index(min(history.history['val_loss']))\n",
        "\n",
        "# Number of epochs trained before early stopping\n",
        "epochs_trained = best_epoch + 1\n",
        "print(\"Number of epochs trained:\", epochs_trained)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZlXMPFuyRkN",
        "outputId": "5eed82f5-e218-4f0e-e6f2-e8c3168cf2cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "26/26 [==============================] - 9s 82ms/step - loss: 3.0500 - accuracy: 0.3060 - val_loss: 2.0685 - val_accuracy: 0.4118\n",
            "Epoch 2/50\n",
            "26/26 [==============================] - 1s 39ms/step - loss: 1.9529 - accuracy: 0.4186 - val_loss: 2.0553 - val_accuracy: 0.4118\n",
            "Epoch 3/50\n",
            "26/26 [==============================] - 1s 30ms/step - loss: 1.8568 - accuracy: 0.4247 - val_loss: 2.0391 - val_accuracy: 0.4118\n",
            "Epoch 4/50\n",
            "26/26 [==============================] - 1s 26ms/step - loss: 1.6807 - accuracy: 0.4737 - val_loss: 1.8338 - val_accuracy: 0.4559\n",
            "Epoch 5/50\n",
            "26/26 [==============================] - 1s 31ms/step - loss: 1.4628 - accuracy: 0.5275 - val_loss: 1.7963 - val_accuracy: 0.4363\n",
            "Epoch 6/50\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 1.3078 - accuracy: 0.5520 - val_loss: 1.7379 - val_accuracy: 0.4657\n",
            "Epoch 7/50\n",
            "26/26 [==============================] - 1s 32ms/step - loss: 1.0131 - accuracy: 0.6536 - val_loss: 2.0240 - val_accuracy: 0.4559\n",
            "Epoch 8/50\n",
            "26/26 [==============================] - 1s 33ms/step - loss: 0.7040 - accuracy: 0.7540 - val_loss: 2.1679 - val_accuracy: 0.4461\n",
            "Epoch 9/50\n",
            "26/26 [==============================] - 1s 30ms/step - loss: 0.4257 - accuracy: 0.8739 - val_loss: 2.6295 - val_accuracy: 0.4902\n",
            "Epoch 10/50\n",
            "26/26 [==============================] - 1s 35ms/step - loss: 0.1989 - accuracy: 0.9474 - val_loss: 3.6118 - val_accuracy: 0.4167\n",
            "Epoch 11/50\n",
            "26/26 [==============================] - ETA: 0s - loss: 0.0968 - accuracy: 0.9731Restoring model weights from the end of the best epoch: 6.\n",
            "26/26 [==============================] - 1s 34ms/step - loss: 0.0968 - accuracy: 0.9731 - val_loss: 3.7210 - val_accuracy: 0.4216\n",
            "Epoch 11: early stopping\n",
            "Number of epochs trained: 6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Use only if need to train model 2 times (when dataset too huge)"
      ],
      "metadata": {
        "id": "mvA5YUbRkvGL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Part 1"
      ],
      "metadata": {
        "id": "TQ6N-1bZk07t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "epochs=50\n",
        "\n",
        "# EarlyStopping will stop training if validation loss doesn't improve\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss', patience=5, verbose=1, restore_best_weights=True)\n",
        "\n",
        "checkpoint = ModelCheckpoint('/content/drive/MyDrive/2023_internship/dataset_20200803/model0_phase1.h5', save_best_only=True)\n",
        "\n",
        "# Train your model\n",
        "history = model_1.fit(\n",
        "    train_ds_part1,\n",
        "    validation_data=val_ds,\n",
        "    epochs=epochs,\n",
        "    callbacks=[early_stopping, checkpoint]\n",
        ")\n",
        "\n",
        "# Find the index where validation loss is minimized\n",
        "best_epoch = history.history['val_loss'].index(min(history.history['val_loss']))\n",
        "\n",
        "# Number of epochs trained before early stopping\n",
        "epochs_trained = best_epoch + 1\n",
        "print(\"Number of epochs trained:\", epochs_trained)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZvKZVXEYDSWf",
        "outputId": "9ecc4902-df67-4220-a0fc-7e821a66284c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "267/267 [==============================] - 1461s 5s/step - loss: 1.6635 - accuracy: 0.4953 - val_loss: 1.2465 - val_accuracy: 0.6224\n",
            "Epoch 2/50\n",
            "267/267 [==============================] - 42s 154ms/step - loss: 0.8183 - accuracy: 0.7511 - val_loss: 0.7375 - val_accuracy: 0.7870\n",
            "Epoch 3/50\n",
            "267/267 [==============================] - 41s 151ms/step - loss: 0.3407 - accuracy: 0.8984 - val_loss: 0.6164 - val_accuracy: 0.8390\n",
            "Epoch 4/50\n",
            "267/267 [==============================] - 41s 150ms/step - loss: 0.1328 - accuracy: 0.9630 - val_loss: 0.5093 - val_accuracy: 0.8823\n",
            "Epoch 5/50\n",
            "267/267 [==============================] - 41s 149ms/step - loss: 0.0727 - accuracy: 0.9800 - val_loss: 0.5235 - val_accuracy: 0.9096\n",
            "Epoch 6/50\n",
            "267/267 [==============================] - 40s 148ms/step - loss: 0.0570 - accuracy: 0.9833 - val_loss: 0.5826 - val_accuracy: 0.9190\n",
            "Epoch 7/50\n",
            "267/267 [==============================] - 39s 145ms/step - loss: 0.0590 - accuracy: 0.9843 - val_loss: 0.6766 - val_accuracy: 0.8949\n",
            "Epoch 8/50\n",
            "267/267 [==============================] - 39s 142ms/step - loss: 0.0672 - accuracy: 0.9812 - val_loss: 0.6952 - val_accuracy: 0.9010\n",
            "Epoch 9/50\n",
            "267/267 [==============================] - ETA: 0s - loss: 0.0495 - accuracy: 0.9857Restoring model weights from the end of the best epoch: 4.\n",
            "267/267 [==============================] - 40s 147ms/step - loss: 0.0495 - accuracy: 0.9857 - val_loss: 0.5819 - val_accuracy: 0.9157\n",
            "Epoch 9: early stopping\n",
            "Number of epochs trained: 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Part 2"
      ],
      "metadata": {
        "id": "iB3fggstk3yE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the saved model's weights from the first phase\n",
        "model_1.load_weights('/content/drive/MyDrive/2023_internship/dataset_20200803/model0_phase1.h5')\n",
        "\n",
        "checkpoint = ModelCheckpoint('/content/drive/MyDrive/2023_internship/dataset_20200803/model0_phase2.h5', save_best_only=True)\n",
        "\n",
        "# Continue training the model on the remaining part of the dataset\n",
        "history_phase2 = model_1.fit(\n",
        "    train_ds_part2,\n",
        "    validation_data=val_ds,\n",
        "    epochs=epochs,\n",
        "    callbacks=[early_stopping, checkpoint]\n",
        ")\n",
        "\n",
        "# Find the index where validation loss is minimized\n",
        "best_epoch = history.history['val_loss'].index(min(history.history['val_loss']))\n",
        "\n",
        "# Number of epochs trained before early stopping\n",
        "epochs_trained = best_epoch + 1\n",
        "print(\"Number of epochs trained:\", epochs_trained)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "er_XnaZQR313",
        "outputId": "ef2bf77b-e7e1-4d4b-c149-940792238f23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "267/267 [==============================] - 910s 3s/step - loss: 0.2866 - accuracy: 0.9273 - val_loss: 0.1481 - val_accuracy: 0.9581\n",
            "Epoch 2/50\n",
            "267/267 [==============================] - 72s 145ms/step - loss: 0.0465 - accuracy: 0.9882 - val_loss: 0.0890 - val_accuracy: 0.9721\n",
            "Epoch 3/50\n",
            "267/267 [==============================] - 72s 142ms/step - loss: 0.0310 - accuracy: 0.9924 - val_loss: 0.0942 - val_accuracy: 0.9787\n",
            "Epoch 4/50\n",
            "267/267 [==============================] - 72s 145ms/step - loss: 0.0698 - accuracy: 0.9785 - val_loss: 0.1612 - val_accuracy: 0.9455\n",
            "Epoch 5/50\n",
            "267/267 [==============================] - 75s 157ms/step - loss: 0.0515 - accuracy: 0.9861 - val_loss: 0.0877 - val_accuracy: 0.9717\n",
            "Epoch 6/50\n",
            "267/267 [==============================] - 73s 144ms/step - loss: 0.0113 - accuracy: 0.9973 - val_loss: 0.0481 - val_accuracy: 0.9860\n",
            "Epoch 7/50\n",
            "267/267 [==============================] - 72s 144ms/step - loss: 0.0088 - accuracy: 0.9984 - val_loss: 0.0626 - val_accuracy: 0.9810\n",
            "Epoch 8/50\n",
            "267/267 [==============================] - 72s 147ms/step - loss: 0.0141 - accuracy: 0.9959 - val_loss: 0.1941 - val_accuracy: 0.9494\n",
            "Epoch 9/50\n",
            "267/267 [==============================] - 73s 149ms/step - loss: 0.0629 - accuracy: 0.9810 - val_loss: 0.2064 - val_accuracy: 0.9375\n",
            "Epoch 10/50\n",
            "267/267 [==============================] - 71s 143ms/step - loss: 0.0239 - accuracy: 0.9927 - val_loss: 0.1271 - val_accuracy: 0.9642\n",
            "Epoch 11/50\n",
            "267/267 [==============================] - ETA: 0s - loss: 0.0142 - accuracy: 0.9960Restoring model weights from the end of the best epoch: 6.\n",
            "267/267 [==============================] - 90s 184ms/step - loss: 0.0142 - accuracy: 0.9960 - val_loss: 0.1338 - val_accuracy: 0.9707\n",
            "Epoch 11: early stopping\n",
            "Number of epochs trained: 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save the Model"
      ],
      "metadata": {
        "id": "KUsPJty9DZcx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.save('/content/drive/MyDrive/flirModel_withSharpenedBrightened_onlyFlipped.keras')"
      ],
      "metadata": {
        "id": "P3k1eyLhDZ_P"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}